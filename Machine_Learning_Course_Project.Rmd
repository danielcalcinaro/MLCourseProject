---
title: "Course Project Machine Learning"
author: "Dani"
date: "18 de mayo de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 


## Objective

In this project, our goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise. 


## Analysis

First I store the training set in a variable named pml, and take a look at it:

```{r pml}


pml<-read.csv("pml-training.csv")

summary(pml)

```

This data set contains `r dim(pml)[1]` rows and `r dim(pml)[2]` columns.

As we can see, there are several fields with NA values. I will define a new data set leaving those fields out:

```{r}
pml_SA<-pml[colSums(is.na(pml))==0]

```

Now we have `r dim(pml_SA)[2]` columns.

Let's take a closer look at this reduced data set:

We have taken out the NA values, but there are still some fields have weird values, like results of a division by zero or empty values. In particular, there is something wrong in every field related to kurtosis, skeness or amplitudes. We will define a new data set leaving those fields out, as well as those starting with 'min_yaw' or 'max_yaw':


```{r}
pml_SAr<-pml_SA[substr(names(pml_SA),1,4)!="kurt" & substr(names(pml_SA),1,4)!="skew" & substr(names(pml_SA),1,4)!="ampl" & substr(names(pml_SA),5,7)!="yaw"]
```


The 1st column is not providing any information. Neither does the 3rd one, since it is constant. In a similar way, we will leave out columns 4 to 7:

```{r}

pml_SArr<-pml_SAr[-c(1,3:7)]


```


We reduced it to `r dim(pml_SArr)[2]` columns.

Let's take a look at them:


```{r}
str(pml_SArr)
```

Data looks much cleaner now, so we will use this `r dim(pml_SArr)[2]` by `r dim(pml_SArr)[1]` data set to train and test models in order to select the most accurate.

First, we will create a partition in the data set, setting a 70% of it as  the training data:

```{r training}

library(caret)

set.seed(1000)

inTrain<-createDataPartition(y=pml_SArr$classe,p=0.7,list=FALSE)

pml_SArr_train<-pml_SArr[inTrain,]

pml_SArr_test<-pml_SArr[-inTrain,]


```

Then we will use `r dim(pml_SArr_train)[1]` rows to train the models and `r dim(pml_SArr_test)[1]` to test them.

Now that we have created the partition, we will train our first model LDA:

```{r lda}

model_lda<-train(classe~.,data=pml_SArr_train,method="lda")

```

We will use this model to predict the variable 'classe' on the subset that we created to test our models:

```{r}
predict_lda<-predict(model_lda,newdata=pml_SArr_test)
```

and we can now test its accuracy by comparing with the actual classe in the testing set. This leads to a `r confusionMatrix(predict_lda,pml_SArr_test$classe)$overall[1]` accuracy, which is not that great. We will try a gbm model and check if we can get at least a 95% accuracy:

```{r gbm}

model_gbm<-train(classe~.,data=pml_SArr_train,method="gbm")

predict_gbm<-predict(model_gbm,newdata=pml_SArr_test)

```

This GBM model leads to a very improved accuracy of `r confusionMatrix(predict_gbm,pml_SArr_test$classe)$overall[1]`.

Despite getting a pretty accurate result, we will train and test a Random Forest Model:

```{r rf}

model_rf<-train(classe~.,data=pml_SArr_train,method="rf")

predict_rf<-predict(model_rf,newdata=pml_SArr_test)

confusionMatrix(predict_rf,pml_SArr_test$classe)
```

This Random Forest model leads to an accuracy of `r confusionMatrix(predict_rf,pml_SArr_test$classe)$overall[1]`, which is pretty high and therefore we will select this model.







